% Created 2020-09-05 Sat 22:46
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Robert S. Pratt}
\date{\today}
\title{Data Structures and Algorithms using Java - Chapter 1}
\hypersetup{
 pdfauthor={Robert S. Pratt},
 pdftitle={Data Structures and Algorithms using Java - Chapter 1},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.1 (Org mode 9.4)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Overview and Java Review}
\label{sec:org87e60b5}
\subsection{Data Structures}
\label{sec:org18de5ad}
\subsubsection{What is Data?}
\label{sec:org6f46280}
\begin{itemize}
\item \textbf{data} is information
\item studies show that programs spend 80\% of their execution time searching through memory to locate necessary data
\item \textbf{Data Structres} is the area of computer science that dresses the issues of data storage requirements of a program and the speed at which the program loactes the data it processes
\end{itemize}
\subsubsection{What is a Data Structure?}
\label{sec:org0941551}
\begin{itemize}
\item a \textbf{data structure} is an organization of information, usually in memory, for better algorithm efficiency
\item \textbf{overhead} is the extra storage above the size of the data set that an organization scheme requires
\item a good data structure is one that organizes the data in a way that facilitates the operations performed on the data
\begin{itemize}
\item it does this while keeping total storage requirements at, or close to, the size of the data set
\end{itemize}
\item there are two types of of data structures:
\begin{enumerate}
\item built-in data structures
\begin{itemize}
\item scemes for storing data that are part of a programming language
\begin{itemize}
\item examples include memory cell (variable) declarations, arrays, and Java's String class
\end{itemize}
\end{itemize}
\item programmer-defined data structures
\begin{itemize}
\item schemes for storing data that are conceived and implemented by the programmer of a particular program
\begin{itemize}
\item examples of these are parallel arrays, class definitions, hashing schemes, linked lists, trees, stacks, and queues
\end{itemize}
\end{itemize}
\end{enumerate}
\end{itemize}

\subsection{Selecting a Data Structure}
\label{sec:orgbbdd5be}
\subsubsection{The Data Structure's Impact on PErformance}
\label{sec:org5142eff}


\subsubsection{Determining the PErformance of a Data Structure}
\label{sec:orgec39950}
\begin{itemize}
\item evaluation takes place during the early design stages, before any code is written
\item two sets of calculations are performed on each candidate data structure to measure its performance:
\begin{enumerate}
\item calculations to determine the speed of the operations to be performed on the data
\item calculations to determine the amount of overhead associated with the data structure
\end{enumerate}
\item the best structure for a particular application is usually a compromise between speed, overhead, and cost
\end{itemize}
\subsubsection{The Trade-Off Process}
\label{sec:org6337a27}
\begin{itemize}
\item the selection of the best data structure should always be based on:
``the least expenseive data structure that satisfies the speed requirements and storage constraints of the application''
\item when data processing is performed to update a display viewed by humans, an operation time of 0.1 is more than adequate
\begin{itemize}
\item studies show that faster response times are impercetible to humans
\end{itemize}
\item software engineering practices mandate that speed requirements be specified before tue program is designed
\begin{itemize}
\item they must be documented in the project's \emph{Requirements Document}
\end{itemize}
\item cost of a data structure is primarily the labor cost of developing the code to implement it
\begin{itemize}
\item this includes its design, coding, testing, and documentation
\item studies indicate that the cost of software is directly proportional to the number of lines of code that the software contains
\end{itemize}
\end{itemize}

\subsection{Fundamental Concepts}
\label{sec:orgbaf55e0}
\subsubsection{Terminology}
\label{sec:org1361b10}
\begin{itemize}
\item \textbf{field} - an indivisible piece of data
\begin{itemize}
\item \emph{indivisible} means that if the data were divided any further, it would lose all meaning
\end{itemize}
\item \textbf{node} - a group of related fields
\item \textbf{key field} - a designated field in a node whose contents are used to identify, or refer to, the node
\item \textbf{homogeneous data set} - a set of nodes in which all the nodes have identical fields (number and type)
\begin{itemize}
\item most data sets are homogeneous
\end{itemize}
\end{itemize}
\subsubsection{Access Modes}
\label{sec:org2173997}
\begin{itemize}
\item \emph{access} is the process by which a node is located in memory
\begin{itemize}
\item once located, and \emph{operation} can be performed on the node
\end{itemize}
\item there are two generic ways or modes used to specify the node to be accessed:
\begin{enumerate}
\item the node number mode
\begin{itemize}
\item the number of the node is specified
\end{itemize}
\item the key field mode
\begin{itemize}
\item the contents of the designated key field are specified
\end{itemize}
\end{enumerate}
\item most data structures utilize the key field access mode
\end{itemize}
\subsubsection{Linear Lists}
\label{sec:org0411915}
\begin{itemize}
\item a collection of \emph{n} nodes is a linear list if:
\begin{itemize}
\item there is a unique first node, N\textsubscript{1}
\item there is a unique last node, N\textsubscript{n}
\item for any other node, N\textsubscript{i}, a unique node, N\textsubscript{i}-1, comes before it and a unique node, N\textsubscript{i}+1, comes after it
\end{itemize}
\end{itemize}
\subsubsection{Data Structure Operations}
\label{sec:orgc51e5dd}
\begin{itemize}
\item operations performed on data structures can be arranged in a hierarchy.
\item the most fundamental operation is \emph{insert}
\begin{itemize}
\item \emph{insert} adds a node to the data structure
\item this is the most fundamental operation because all data sets would be empty without it and os it must be available for all data sets
\end{itemize}
\item the next level of operation hierarchy includes \emph{fetch} and \emph{delete}
\begin{itemize}
\item \emph{fetch} returns a node from the data set
\item \emph{delete} elimates a node from the data set
\end{itemize}
\item the \emph{update} operation is a level above \emph{fetch} and \emph{delete}
\begin{itemize}
\item it is considered higher because it can be implemented to \emph{delete} a node and then \emph{insert} a new one in its place
\item all fields of a node must be supplied to a \emph{node} during an \emph{update} operation, even if only one is being updated
\end{itemize}
\end{itemize}
\subsubsection{Implementing a Programmer-Defined Data Structure}
\label{sec:org73b0ef0}
\begin{itemize}
\item in OOP languages, data structures are implemented using the class construct
\begin{itemize}
\item the memory required for the data structure is specified as the class's data members and the operations are stored as methods
\end{itemize}
\item the best way to implement a data structure is to implement it as a \emph{generic} data stracture
\begin{itemize}
\item generic data structures are implemented in such a way that they can be used for multiple applications, regardless of node strtucture
\item they reduce the cost of software development because, once coded for an application, they do not need to be recoded for subsequent applications
\end{itemize}
\item guidelines for the implementation of a data structure in a generic way:
\begin{itemize}
\item node definition and data structure are coded as separate classes
\item node definition class (\emph{interface} class):
\begin{itemize}
\item always contains a data member for each field
\item usually contains a toString method to facilitate the output of fields
\end{itemize}
\item data structure class (\emph{implementation} class):
\begin{itemize}
\item allocates storage to maintain overhead
\item allocates storage for the data set
\item provides initialization methods
\item provides methods to perform the required operations
\item usually provides a method to display the contents of all nodes
\end{itemize}
\end{itemize}
\end{itemize}
\subsubsection{Procedural Abstractions and Abstract Data Types}
\label{sec:org56eeea8}
\begin{itemize}
\item in computer science, we encounter two abstractions:
\begin{enumerate}
\item procedural abstractions
\begin{itemize}
\item the implementation details of a method/procedure do not need to be known to use it
\end{itemize}
\item data abstractions
\begin{itemize}
\item the implementation details of a data structure do not need to be known to use it
\item only the the operation methods and their signatures need to be known so they can be used
\end{itemize}
\end{enumerate}
\item an \textbf{abstract data type} is a data structure that can be used with only this superficial level of understanding
\item \textbf{standard abstract data type} is a data structure whose operation method signatures conform to a consistent format
\begin{itemize}
\item this standardization provides the benefit that a programmer can change the data structure used in an existing application by changing one line: the line that declares the data structure object
\item standardizing abstract data types reduces the cost of software
\end{itemize}
\end{itemize}
\subsubsection{Encapsulation}
\label{sec:org488b21d}
\begin{itemize}
\item \textbf{encapsulation} is the idea that code is written in a way that establishes \emph{compiler enforced protocols} for accessing the data that a program processes
\item these protocols usually \emph{restrict} access to the data
\item in computer science, it is said that encapsulation limits the \emph{scope} of the program statements that can acecss a data item
\item \textbf{modularization} all methods dealing with encapsulated code are contained with in the same class
\end{itemize}

\subsection{Calculating Speed (Time Complexity)}
\label{sec:orga85943a}
\begin{itemize}
\item \textbf{wall time} is the considered speed of an algorithm in seconds
\item \emph{complexity analysis} is used to remove platform-dependent factors that provide variance in estimated wall time execution
\begin{itemize}
\item \emph{time complexity} is from a speed viewpoint
\begin{itemize}
\item expressed as a mathematical function T(n), where \emph{n} is usually the number of pieces of data the algorithm processes
\end{itemize}
\item \emph{space complexity} is from a storage viewpoint
\end{itemize}
\item \emph{Big-O Analysis} can be used to greatly simplify complexity analysis
\end{itemize}
\subsubsection{Big-O Analysis (O Standing for \_O\textsubscript{rder} of Magnitude)}
\label{sec:org4508035}
\begin{itemize}
\item used to set a boind on the upper limit of a mathematical function
\begin{itemize}
\item based on the assumption that one of the terms of the function will \emph{dominate}, or contribute, all but a negligible portion of the fuction's value
\end{itemize}
\item provides the following guideline:
to approximate the value of a function of \emph{n}, as \emph{n} gets large, it is sufficient to identify its dominant term and evaluate it for adequately large values of \emph{n}
\item used to evaluate functional relationships in all fields of engineering
\begin{itemize}
\item however, in software engineering, its use to evaluate the speed of an algorithm is simpler than its use in other engineering disciplines because of the limited number of functions that result from the analysis of algorithm complexity
\end{itemize}
\item two other analysis techniques used to determine the \emph{approximate} value of a mathematical function:
\begin{itemize}
\item Big-Omega
\begin{itemize}
\item used to determine the lower bound
\end{itemize}
\item Big-Theta
\begin{itemize}
\item used to analyze functions whose upper and lower bounds are of the same order of magnitude
\end{itemize}
\end{itemize}
\end{itemize}
\subsubsection{Algorithm Speed}
\label{sec:org9ec8c31}
\begin{itemize}
\item two factors to consider when discussing algorithm speed:
\begin{enumerate}
\item the \emph{relative} speed of the algorithm to other algorithms
\begin{itemize}
\item used to determine whether an algorithm (or code segment) is faster or slower than other algorithms
\end{itemize}
\item the \emph{absolute} speed of the algorithm
\begin{itemize}
\item used to determine the actual execution time, in seconds, of the algorithm
\end{itemize}
\end{enumerate}
\item both speeds can be simplified using Big-O analysis, though its approximation may invalidate its use for calculating absolute speed for some time-critical applications
\end{itemize}
\subsubsection{Relative Speed of Algorithms}
\label{sec:org4c08a69}
\begin{itemize}
\item relative speed is determined by analyzing each algorithm's pseudocode to determing their speed function's dominant term.
\begin{itemize}
\item the fastest algorithm is the one whose dominant term occupies the highest position in the following table; the slowest has a dominant term in the lowest position
\end{itemize}
\end{itemize}
\textbf{Relative Dominance of Common Algorithm Complexity Terms}
\begin{center}
\begin{tabular}{llr}
Dominant Term & Name of Dominant Term & Relative Magnitude of the Dominant Term\\
\hline
\emph{c}, a constant & Constant & Relative Magnitude of the Dominant Term\\
log\textsubscript{2}(\emph{n}) & Logarithmic & 2\\
\emph{n} & Linear & 3\\
\emph{n/log\textsubscript{2}(/n}) & Linear logarithmic & 4\\
Powers of \emph{n}: \emph{n/\textsuperscript{2} < /n/\textsuperscript{3} < \ldots{} < /n/\^{}/i} (\emph{i} < \emph{n}) & Polynomial & 5\\
\emph{c/\^{}/n} & Exponential & 6\\
\emph{n}! & Factorial & 7 (largest)\\
\end{tabular}
\end{center}

\begin{enumerate}
\item Relative Speed Case Study: The Binary Search Algorithm
\label{sec:orgc92bae4}
\begin{itemize}
\item the binary search algorithm is a technique for finding a data item stored in an array
\begin{itemize}
\item given the data item, called the \emph{search value} the algorith returns the item's array index value
\item the algorithm \emph{assumes} the array is sorted (this case study assumes ascending order)
\end{itemize}
\item the algorithm idententifies a portion of the array that includes the serach value as a \emph{sub-array}
\begin{itemize}
\item initially, the entire array is the sub-array
\end{itemize}
\end{itemize}
\end{enumerate}
\subsubsection{Absolute Speed of an Algorithm}
\label{sec:org9875ed9}
\begin{itemize}
\item the fastest algorithm identified by Big-O analysis might not always be fast enough for an application
\item the most reliable way to determine the absoute speed of an algorithm is code it and test it on a representative number of preocesses
\begin{itemize}
\item this is often to time consuming and costly to implement during the design process
\end{itemize}
\item assuming the CPU is dedicated to the execution of the algorithm, execution time, \emph{t}, can be expressed as:
\emph{t} = \emph{t/\_/m/1 + /t/\_/m/2 + \ldots{} + /t/\_/m//n}
\begin{itemize}
\item where \emph{n} is the total number of machine language instructions in the translation of the algorithm
and
\item \emph{t/\_/m//i} is the time required to execute the /i/th machine language instruction
\item this equation can be simplified down to:
g
\(\Sigma\) (\emph{t/\_/i} * \emph{n/\_/i})
/i/=1
\begin{itemize}
\item \emph{g} is the number of instruction groupings
\item \emph{t/\_/i} is the time required to execute an instruction in the /i/th grouping
and
\item \emph{n/\_/i} is the number of instructions in group \emph{i}
\end{itemize}
\end{itemize}
\item in the simplest case, instructions are assumed to be in one of two groups (\emph{g} = 2)
\begin{enumerate}
\item those that access memory
\item those that do not access memory
\end{enumerate}
\item distinguishing between instructions that do and do not access memory is import because accessing memory is significantly slower than those that do not
\begin{itemize}
\item instructions that do not access memory are called \emph{nonaccess} instructions
\item speed of memory is orders of magnitude slower than CPU logic operation performance time
\end{itemize}
\end{itemize}

\subsubsection{Data Structure Speed}
\label{sec:org747f8c0}
\begin{itemize}
\item speed of an algorithm's operations is not the only factor; \emph{frequency} of each operation is also important
\item the frequency-weighted average time is defined as:
\emph{t/\textsubscript{avg} = (/t/\textsubscript{1} * /f/\textsubscript{1} + /t/\textsubscript{2} * /f/\textsubscript{2} + /t/\textsubscript{3} * /f/\textsubscript{3} + \ldots{} /t/\textsubscript{n} * /f/\_/n})/(\emph{f/\textsubscript{1} + /f/\textsubscript{2} + /f/\textsubscript{3} + \ldots{} + /f/\_/n})
\begin{itemize}
\item \emph{t/\_/i} is the speed of the \emph{i/th operation (/i} = 1, 2, 3, \ldots{}, \emph{n})
\item \emph{n} is the number of different operations available on the structure
and
\item \emph{f/\_/i} is the frequency of the \emph{i/th operation (/i} = 1, 2, 3, \ldots{}, \emph{n})
\end{itemize}
\item the equation for \emph{t/\textsubscript{avg} can be expressed in a simpler form where the denominator is divided into each term of the numberator:
/t/\textsubscript{avg} = (/t/\textsubscript{1} * \(\rho\)\textsubscript{1} + /t/\textsubscript{2} * \(\rho\)\textsubscript{2} + /t/\textsubscript{3} + \(\rho\)\textsubscript{3} + \ldots{} + /t/\_/n} * \(\rho\)\_/n/)
\begin{itemize}
\item \(\rho\)\_/i/ is the probability of the \emph{i/th operation and is equal to /f/\_/i} / (\emph{f/\textsubscript{1} + /f/\textsubscript{2} + /f/\textsubscript{3} + \ldots{} /f/\_/n})
\end{itemize}
\end{itemize}

\subsection{Calculating Memory Overhead (Space Complexity)$\backslash$}
\label{sec:orge949c91}
\begin{itemize}
\item data structures that minimize overhead are said to be more \emph{memory efficient}
\item the parameter/metric used to specific how efficiently a data structure uses memory is \emph{density}
\item \emph{Density}, \emph{D}, is defined as:
D = (information bytes)/(total bytes) = (information bytes)/(information bytes + overhead bytes)
\begin{itemize}
\item \emph{information bytes} is the amount of memory required to store the information stored in teh structure, in bytes
\item \emph{total bytes} is the total amount of memory allocated to the structure, in bytes
and
\item \emph{overhead bytes} is the amount of memory required to maintain the structure, in bytes
\end{itemize}
\item the range of \emph{D} is 0 < \emph{D} < 1
\begin{itemize}
\item memory efficient structures have a density close to 1
\end{itemize}
\item some data structures require a set/constant amount of overhead, \emph{O}, independent of the number of nodes
\begin{itemize}
\item the density for these structures increases as the number of nodes in the data structure increases:
\emph{D} = \emph{w} * \emph{n} / (\emph{w} * \emph{n} + \emph{O}) = 1 / (1 + \emph{O} / (\emph{w} * \emph{n}))
\begin{itemize}
\item \emph{w} is the node width and is constant for a particular data structure
\item \emph{n} is the number nodes in the data structre
\end{itemize}
\end{itemize}
\end{itemize}

\subsection{Java Review}
\label{sec:org99aa8b5}
\subsubsection{Arrays of Primitive Variables}
\label{sec:org7fa9008}
\begin{itemize}
\item \emph{primitive variables} are single instances of integral or real types of information
\item \emph{duplicate definition} compile error happens when a reference variable is declared more than once
\end{itemize}
\subsubsection{Definition of a Class}
\label{sec:org78fdaf5}
\begin{itemize}
\item a \textbf{class} is a programmer-defined type that ocnsists of data definitions and methods (subprograms) that operate on that data
\item the name of the class is the name of the newly defined data type
\item each class and method will have an \emph{access modifier} that determines whether or not other parts of the program can interact with it
\item an instance of a class is called an \emph{object}
\item there are two penmanship issues to follow when coding classes:
\begin{enumerate}
\item names of classes should always beging with an uppercase letter
\item names of data members and methods should be in Pascal Case
\end{enumerate}
\item parameter names used in method headings should not be the same as the names of data members
\end{itemize}
\subsubsection{Declaration of an Object}
\label{sec:org68d4a5a}
\begin{itemize}
\item the sequence of code that declares the object is referred to as \emph{client code}
\end{itemize}
\subsubsection{Declaration of an Array of Ojects}
\label{sec:org9233bde}
\begin{itemize}
\item an array of objects is declared using a three-step process:
\begin{enumerate}
\item declare a reference variable to store the location of the first element of the array
\item declare an array of \emph{n} reference variables to store the address of the \emph{n} objects
\item declare the \emph{n} objects, setting their locations into the array of reference variables
\end{enumerate}
\end{itemize}
\subsubsection{Objects that Contain Objects as Data Members}
\label{sec:orgbd53cc0}
\begin{itemize}
\item objects can contain other objects as their parameters
\end{itemize}
\end{document}
